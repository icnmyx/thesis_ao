ModelA(
  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn12): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn22): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn32): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (dropout1): Dropout(p=0.1, inplace=False)
  (fc1): Linear(in_features=16384, out_features=1, bias=True)
  (fc2): Linear(in_features=256, out_features=1, bias=True)
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
--
Experiment Parameters:
Loss Func: L1 - Closed/Open: Closed - Batch Size: 64 - Epochs: 300 - Learning Rate: 0.002
--
Epoch [1/300] - 0.2067/0.0092/0.2067/0.0092
Epoch [2/300] - 0.0052/0.0176/0.0052/0.0176
Epoch [3/300] - 0.0085/0.0043/0.0085/0.0043
Epoch [4/300] - 0.0064/0.0050/0.0064/0.0050
Epoch [5/300] - 0.0055/0.0381/0.0055/0.0381
Epoch [6/300] - 0.0052/0.0504/0.0052/0.0504
Epoch [7/300] - 0.0049/0.0037/0.0049/0.0037
Epoch [8/300] - 0.0046/0.0223/0.0046/0.0223
Epoch [9/300] - 0.0043/0.0274/0.0043/0.0274
Epoch [10/300] - 0.0042/0.0354/0.0042/0.0354
--
Best Result: Epoch [7/300] - Val Loss: 0.0037, Val Error: 0.0037
--
Epoch [11/300] - 0.0040/0.0270/0.0040/0.0270
Epoch [12/300] - 0.0039/0.0045/0.0039/0.0045
Epoch [13/300] - 0.0035/0.0047/0.0035/0.0047
Epoch [14/300] - 0.0036/0.0144/0.0036/0.0144
Epoch [15/300] - 0.0033/0.0204/0.0033/0.0204
Epoch [16/300] - 0.0033/0.0368/0.0033/0.0368
Epoch [17/300] - 0.0033/0.0223/0.0033/0.0223
Epoch [18/300] - 0.0032/0.0286/0.0032/0.0286
Epoch [19/300] - 0.0032/0.0390/0.0032/0.0390
Epoch [20/300] - 0.0031/0.0111/0.0031/0.0111
--
Best Result: Epoch [7/300] - Val Loss: 0.0037, Val Error: 0.0037
--
Epoch [21/300] - 0.0030/0.0075/0.0030/0.0075
Epoch [22/300] - 0.0030/0.0103/0.0030/0.0103
Epoch [23/300] - 0.0030/0.0318/0.0030/0.0318
Epoch [24/300] - 0.0029/0.0078/0.0029/0.0078
Epoch [25/300] - 0.0030/0.0380/0.0030/0.0380
Epoch [26/300] - 0.0029/0.0213/0.0029/0.0213
Epoch [27/300] - 0.0029/0.0271/0.0029/0.0271
Epoch [28/300] - 0.0028/0.0292/0.0028/0.0292
Epoch [29/300] - 0.0029/0.0260/0.0029/0.0260
Epoch [30/300] - 0.0028/0.0432/0.0028/0.0432
--
Best Result: Epoch [7/300] - Val Loss: 0.0037, Val Error: 0.0037
--
Epoch [31/300] - 0.0028/0.0271/0.0028/0.0271
Epoch [32/300] - 0.0028/0.0298/0.0028/0.0298
Epoch [33/300] - 0.0028/0.0287/0.0028/0.0287
Epoch [34/300] - 0.0028/0.0161/0.0028/0.0161
Epoch [35/300] - 0.0028/0.0255/0.0028/0.0255
Epoch [36/300] - 0.0027/0.0422/0.0027/0.0422
Epoch [37/300] - 0.0028/0.0121/0.0028/0.0121
Epoch [38/300] - 0.0027/0.0040/0.0027/0.0040
Epoch [39/300] - 0.0027/0.0285/0.0027/0.0285
Epoch [40/300] - 0.0027/0.0054/0.0027/0.0054
--
Best Result: Epoch [7/300] - Val Loss: 0.0037, Val Error: 0.0037
--
Epoch [41/300] - 0.0027/0.0191/0.0027/0.0191
Epoch [42/300] - 0.0026/0.0228/0.0026/0.0228
Epoch [43/300] - 0.0027/0.0072/0.0027/0.0072
Epoch [44/300] - 0.0026/0.0362/0.0026/0.0362
Epoch [45/300] - 0.0026/0.0180/0.0026/0.0180
Epoch [46/300] - 0.0027/0.0163/0.0027/0.0163
Epoch [47/300] - 0.0026/0.0107/0.0026/0.0107
Epoch [48/300] - 0.0026/0.0273/0.0026/0.0273
Epoch [49/300] - 0.0026/0.0062/0.0026/0.0062
Epoch [50/300] - 0.0026/0.0081/0.0026/0.0081
--
Best Result: Epoch [7/300] - Val Loss: 0.0037, Val Error: 0.0037
--
Epoch [51/300] - 0.0026/0.0357/0.0026/0.0357
Epoch [52/300] - 0.0026/0.0111/0.0026/0.0111
Epoch [53/300] - 0.0026/0.0081/0.0026/0.0081
Epoch [54/300] - 0.0026/0.0187/0.0026/0.0187
Epoch [55/300] - 0.0026/0.0148/0.0026/0.0148
Epoch [56/300] - 0.0026/0.0262/0.0026/0.0262
Epoch [57/300] - 0.0026/0.0396/0.0026/0.0396
Epoch [58/300] - 0.0025/0.0239/0.0025/0.0239
Epoch [59/300] - 0.0025/0.0186/0.0025/0.0186
Epoch [60/300] - 0.0025/0.0195/0.0025/0.0195
--
Best Result: Epoch [7/300] - Val Loss: 0.0037, Val Error: 0.0037
--
Epoch [61/300] - 0.0025/0.0238/0.0025/0.0238
Epoch [62/300] - 0.0025/0.0150/0.0025/0.0150
Epoch [63/300] - 0.0025/0.0323/0.0025/0.0323
Epoch [64/300] - 0.0026/0.0164/0.0026/0.0164
Epoch [65/300] - 0.0025/0.0036/0.0025/0.0036
Epoch [66/300] - 0.0025/0.0106/0.0025/0.0106
Epoch [67/300] - 0.0025/0.0322/0.0025/0.0322
Epoch [68/300] - 0.0025/0.0104/0.0025/0.0104
Epoch [69/300] - 0.0025/0.0270/0.0025/0.0270
Epoch [70/300] - 0.0025/0.0297/0.0025/0.0297
--
Best Result: Epoch [65/300] - Val Loss: 0.0036, Val Error: 0.0036
--
Epoch [71/300] - 0.0025/0.0152/0.0025/0.0152
Epoch [72/300] - 0.0025/0.0079/0.0025/0.0079
Epoch [73/300] - 0.0025/0.0295/0.0025/0.0295
Epoch [74/300] - 0.0025/0.0047/0.0025/0.0047
Epoch [75/300] - 0.0025/0.0172/0.0025/0.0172
Epoch [76/300] - 0.0024/0.0226/0.0024/0.0226
Epoch [77/300] - 0.0025/0.0221/0.0025/0.0221
Epoch [78/300] - 0.0025/0.0140/0.0025/0.0140
Epoch [79/300] - 0.0025/0.0019/0.0025/0.0019
Epoch [80/300] - 0.0025/0.0162/0.0025/0.0162
--
Best Result: Epoch [79/300] - Val Loss: 0.0019, Val Error: 0.0019
--
Epoch [81/300] - 0.0025/0.0186/0.0025/0.0186
Epoch [82/300] - 0.0024/0.0052/0.0024/0.0052
Epoch [83/300] - 0.0024/0.0190/0.0024/0.0190
Epoch [84/300] - 0.0025/0.0283/0.0025/0.0283
Epoch [85/300] - 0.0024/0.0121/0.0024/0.0121
Epoch [86/300] - 0.0024/0.0205/0.0024/0.0205
Epoch [87/300] - 0.0025/0.0249/0.0025/0.0249
Epoch [88/300] - 0.0025/0.0221/0.0025/0.0221
Epoch [89/300] - 0.0024/0.0050/0.0024/0.0050
Epoch [90/300] - 0.0024/0.0250/0.0024/0.0250
--
Best Result: Epoch [79/300] - Val Loss: 0.0019, Val Error: 0.0019
--
Epoch [91/300] - 0.0024/0.0246/0.0024/0.0246
Epoch [92/300] - 0.0024/0.0081/0.0024/0.0081
Epoch [93/300] - 0.0024/0.0303/0.0024/0.0303
Epoch [94/300] - 0.0024/0.0259/0.0024/0.0259
Epoch [95/300] - 0.0025/0.0148/0.0025/0.0148
Epoch [96/300] - 0.0024/0.0040/0.0024/0.0040
Epoch [97/300] - 0.0024/0.0201/0.0024/0.0201
Epoch [98/300] - 0.0025/0.0185/0.0025/0.0185
Epoch [99/300] - 0.0024/0.0111/0.0024/0.0111
Epoch [100/300] - 0.0024/0.0240/0.0024/0.0240
--
Best Result: Epoch [79/300] - Val Loss: 0.0019, Val Error: 0.0019
--
Epoch [101/300] - 0.0024/0.0078/0.0024/0.0078
Epoch [102/300] - 0.0024/0.0054/0.0024/0.0054
Epoch [103/300] - 0.0024/0.0299/0.0024/0.0299
Epoch [104/300] - 0.0024/0.0136/0.0024/0.0136
Epoch [105/300] - 0.0024/0.0178/0.0024/0.0178
Epoch [106/300] - 0.0024/0.0155/0.0024/0.0155
Epoch [107/300] - 0.0024/0.0161/0.0024/0.0161
Epoch [108/300] - 0.0024/0.0188/0.0024/0.0188
Epoch [109/300] - 0.0024/0.0210/0.0024/0.0210
Epoch [110/300] - 0.0024/0.0125/0.0024/0.0125
--
Best Result: Epoch [79/300] - Val Loss: 0.0019, Val Error: 0.0019
--
Epoch [111/300] - 0.0024/0.0077/0.0024/0.0077
Epoch [112/300] - 0.0023/0.0048/0.0023/0.0048
Epoch [113/300] - 0.0024/0.0071/0.0024/0.0071
Epoch [114/300] - 0.0024/0.0072/0.0024/0.0072
Epoch [115/300] - 0.0024/0.0064/0.0024/0.0064
Epoch [116/300] - 0.0024/0.0282/0.0024/0.0282
Epoch [117/300] - 0.0024/0.0053/0.0024/0.0053
Epoch [118/300] - 0.0024/0.0204/0.0024/0.0204
Epoch [119/300] - 0.0024/0.0238/0.0024/0.0238
Epoch [120/300] - 0.0024/0.0254/0.0024/0.0254
--
Best Result: Epoch [79/300] - Val Loss: 0.0019, Val Error: 0.0019
--
Epoch [121/300] - 0.0024/0.0085/0.0024/0.0085
Epoch [122/300] - 0.0023/0.0026/0.0023/0.0026
Epoch [123/300] - 0.0023/0.0084/0.0023/0.0084
Epoch [124/300] - 0.0024/0.0048/0.0024/0.0048
Epoch [125/300] - 0.0024/0.0119/0.0024/0.0119
Epoch [126/300] - 0.0024/0.0232/0.0024/0.0232
Epoch [127/300] - 0.0024/0.0086/0.0024/0.0086
Epoch [128/300] - 0.0024/0.0143/0.0024/0.0143
Epoch [129/300] - 0.0024/0.0061/0.0024/0.0061
Epoch [130/300] - 0.0024/0.0030/0.0024/0.0030
--
Best Result: Epoch [79/300] - Val Loss: 0.0019, Val Error: 0.0019
--
